{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-26T07:55:27.880895Z",
     "start_time": "2024-07-26T07:55:21.460129Z"
    }
   },
   "source": [
    "import boto3\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.getenv('BEDROCK_AWS_ACCESS_KEY'),\n",
    "    aws_secret_access_key=os.getenv('BEDROCK_AWS_SECRET_KEY'),\n",
    ")\n",
    "\n",
    "client = session.client(\"bedrock-runtime\", \"us-east-1\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:55:03.195951Z",
     "start_time": "2024-07-26T07:54:59.877948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_aws.chat_models import BedrockChat\n",
    "\n",
    "chat = BedrockChat(\n",
    "    client=client,\n",
    "    model_id=\"meta.llama3-8b-instruct-v1:0\",\n",
    "    model_kwargs={\n",
    "        \"temperature\":0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "chat.predict(\"hello\")"
   ],
   "id": "e401b65410bf6043",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T08:21:12.870745Z",
     "start_time": "2024-07-26T08:21:12.847060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "full_template = \"\"\"\n",
    "{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\n",
    "\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
    "\n",
    "example_template = \"\"\"\n",
    "Here's an example of an interaction:\n",
    "Q: {example_q}\n",
    "A: {example_a}\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "start_template = \"\"\"\n",
    "Now, do this for real!\n",
    "Q: {input}\n",
    "A:\n",
    "\"\"\"\n",
    "start_prompt = PromptTemplate.from_template(start_template)\n",
    "\n",
    "input_prompts = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"start\", start_prompt),\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=input_prompts\n",
    ")\n",
    "\n",
    "pipeline_prompt.input_variables"
   ],
   "id": "620456e4575677d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'example_q', 'example_a', 'input']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T08:24:23.474602Z",
     "start_time": "2024-07-26T08:24:21.763880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    pipeline_prompt.format(\n",
    "        person=\"Elon Musk\",\n",
    "        example_q=\"What's your favorite car?\",\n",
    "        example_a=\"Tesla\",\n",
    "        input=\"What's your favorite social media site?\",\n",
    "    )\n",
    ")\n",
    "print(\"==================== AI SAYING ====================\")\n",
    "chat.invoke(\n",
    "    pipeline_prompt.format(\n",
    "        person=\"Elon Musk\",\n",
    "        example_q=\"What's your favorite car?\",\n",
    "        example_a=\"Tesla\",\n",
    "        input=\"What's your favorite social media site?\",\n",
    "    )\n",
    ")"
   ],
   "id": "4ac5539883dac7cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are impersonating Elon Musk.\n",
      "\n",
      "Here's an example of an interaction:\n",
      "\n",
      "Q: What's your favorite car?\n",
      "A: Tesla\n",
      "\n",
      "Now, do this for real!\n",
      "\n",
      "Q: What's your favorite social media site?\n",
      "A:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Twitter, of course! It's the only platform that truly allows for real-time, unfiltered communication. And, let's be honest, it's the best way to get my thoughts and ideas out to the world. #Tesla #SpaceX #FutureOfHumanity\", additional_kwargs={'usage': {'prompt_tokens': 57, 'completion_tokens': 55, 'total_tokens': 112}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-8b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 57, 'completion_tokens': 55, 'total_tokens': 112}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-8b-instruct-v1:0'}, id='run-622a373d-30db-4a6d-82d8-8059236d8de9-0', usage_metadata={'input_tokens': 57, 'output_tokens': 55, 'total_tokens': 112})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b5885b70e1486cea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
