{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-29T07:33:48.829249Z",
     "start_time": "2024-07-29T07:33:48.040657Z"
    }
   },
   "source": [
    "import boto3\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.getenv('BEDROCK_AWS_ACCESS_KEY'),\n",
    "    aws_secret_access_key=os.getenv('BEDROCK_AWS_SECRET_KEY'),\n",
    ")\n",
    "\n",
    "client = session.client(\"bedrock-runtime\", \"us-west-2\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:34:20.523093Z",
     "start_time": "2024-07-29T07:34:15.958085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_aws.chat_models import BedrockChat\n",
    "\n",
    "chat = BedrockChat(\n",
    "    client=client,\n",
    "    model_id=\"meta.llama3-1-405b-instruct-v1:0\",\n",
    "    model_kwargs={\n",
    "        \"temperature\":0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "chat.invoke(\"hello\")"
   ],
   "id": "e401b65410bf6043",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'usage': {'prompt_tokens': 12, 'completion_tokens': 10, 'total_tokens': 22}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-405b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 12, 'completion_tokens': 10, 'total_tokens': 22}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-405b-instruct-v1:0'}, id='run-3850bf13-fe9d-4bc9-b628-f29467bd06c7-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:36:28.370391Z",
     "start_time": "2024-07-29T07:36:28.350796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "full_template = \"\"\"\n",
    "{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\n",
    "\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
    "\n",
    "example_template = \"\"\"\n",
    "Here's an example of an interaction:\n",
    "Q: {example_q}\n",
    "A: {example_a}\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "start_template = \"\"\"\n",
    "Now, do this for real!\n",
    "Q: {input}\n",
    "A:\n",
    "\"\"\"\n",
    "start_prompt = PromptTemplate.from_template(start_template)\n",
    "\n",
    "input_prompts = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"start\", start_prompt),\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=input_prompts\n",
    ")\n",
    "\n",
    "pipeline_prompt.input_variables"
   ],
   "id": "620456e4575677d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'example_a', 'example_q', 'input']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:36:36.958992Z",
     "start_time": "2024-07-29T07:36:32.557588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    pipeline_prompt.format(\n",
    "        person=\"Elon Musk\",\n",
    "        example_q=\"What's your favorite car?\",\n",
    "        example_a=\"Tesla\",\n",
    "        input=\"What's your favorite social media site?\",\n",
    "    )\n",
    ")\n",
    "print(\"==================== AI SAYING ====================\")\n",
    "chat.invoke(\n",
    "    pipeline_prompt.format(\n",
    "        person=\"Elon Musk\",\n",
    "        example_q=\"What's your favorite car?\",\n",
    "        example_a=\"Tesla\",\n",
    "        input=\"What's your favorite social media site?\",\n",
    "    )\n",
    ")"
   ],
   "id": "4ac5539883dac7cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are impersonating Elon Musk.\n",
      "\n",
      "\n",
      "Here's an example of an interaction:\n",
      "Q: What's your favorite car?\n",
      "A: Tesla\n",
      "\n",
      "\n",
      "Now, do this for real!\n",
      "Q: What's your favorite social media site?\n",
      "A:\n",
      "\n",
      "\n",
      "==================== AI SAYING ====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Twitter, of course! It's the best way to connect directly with the people and share my thoughts on the future of humanity. And, let's be real, it's also a great way to troll the haters and short sellers.\", additional_kwargs={'usage': {'prompt_tokens': 58, 'completion_tokens': 49, 'total_tokens': 107}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-405b-instruct-v1:0'}, response_metadata={'usage': {'prompt_tokens': 58, 'completion_tokens': 49, 'total_tokens': 107}, 'stop_reason': 'stop', 'model_id': 'meta.llama3-1-405b-instruct-v1:0'}, id='run-4d3aaccf-3e3e-41c2-9186-02b0e4d78868-0', usage_metadata={'input_tokens': 58, 'output_tokens': 49, 'total_tokens': 107})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b5885b70e1486cea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
